{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5e3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## source : https://www.educative.io/courses/langchain-llm/runnables-and-expression-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08f63d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kunal21/opt/miniconda3/envs/v_agentic_kn/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed0bca",
   "metadata": {},
   "source": [
    "### Runnables in LangChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef823b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "GROQ_KEY = os.getenv('GROQ_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f7c743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53555ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model='llama3-8b-8192', #'deepseek-r1-distill-llama-70b',#llama-3.3-70b-versatile\n",
    "               api_key=GROQ_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f00d2",
   "metadata": {},
   "source": [
    "##### Runnables -   Callable unit of work\n",
    "Common methods ; \n",
    "1. invoke() processes a single input and returns a single output, ideal for individual requests.\n",
    "2. batch () allows us to process a list of inputs simultaneously and return a list of corresponding outputs, which is much more efficient for handling multiple requests at once.\n",
    "3. stream() processes a single input but returns an output as a stream of chunks, which is useful for displaying real-time progress or handling very large outputs.\n",
    "\n",
    "- LECL - langchain expressions language : for chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3996eba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1080b1fd0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1080b2ba0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d179f9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would classify this feedback as Positive. The phrase \"delivery was on time\" suggests that the customer is satisfied with the delivery process and the product was received as expected, which is a positive experience.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## simple chain example - input->promptTemplate->parser->output\n",
    "## finding setiment as positive or negative \n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "sentiment_template = PromptTemplate(\n",
    "    input_variables=[\"Feedback\"],\n",
    "    template=\"Determine sentiment of this Feedback as Positive or Negative\\n{Feedback}\"\n",
    ")\n",
    "\n",
    "user_feedback = \"delivery was on time \"\n",
    "\n",
    "chain = sentiment_template | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({'Feedback':user_feedback})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043bd4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5d65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae00cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_agentic_kn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
