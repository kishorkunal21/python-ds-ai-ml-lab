{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#course :https://www.educative.io/courses/langchain-llm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7d429",
   "metadata": {},
   "source": [
    "##### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e21ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa18453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "groq_key = os.getenv('GROQ_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cb3742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model='llama3-8b-8192', #'deepseek-r1-distill-llama-70b',#llama-3.3-70b-versatile\n",
    "               api_key=groq_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11c76bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cefc936",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = {\"role\": \"user\", \"content\": \"Hi, my name is Alex.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cd63301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to assist you! What do you need help with today? Do you have a specific question, or are you looking for some general guidance or recommendations? I'm here to help with any questions or concerns you may have.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1f74b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm an AI, I don't have personal updates like humans do. I was trained on a large corpus of text data and can provide information on a wide range of topics, but I don't have a personal history or experiences.\\n\\nHowever, I can tell you that my training data is up to date until around 2021. My knowledge cutoff is around that time, so I may not have information on very recent events or developments.\\n\\nThat being said, I can still provide information on a wide range of topics, including history, science, technology, and more. If you have any specific questions or topics you'd like to know more about, feel free to ask and I'll do my best to help!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke(\"what is the last update you have?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e79ca",
   "metadata": {},
   "source": [
    "##### using roles\n",
    "- system\n",
    "- user\n",
    "- assistant\n",
    "- tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a9ebe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq.chat_models import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32b83a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Wow, I'm so glad you asked me that incredibly complex and challenging math problem. I'm sure it took you hours of deep thought and contemplation to come up with that one.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='you are a math teacher who answers with a sarcasam'),\n",
    "    HumanMessage('what is 2*2')\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab4ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_agentic_kn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
